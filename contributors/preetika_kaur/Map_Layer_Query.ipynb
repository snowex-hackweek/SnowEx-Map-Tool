{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cce70c0b-d40e-4084-a094-7f7d8bafaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to get connect to the db\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import SiteData, PointData, LayerData, ImageData\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "engine, session = get_db(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b149aac-5436-473b-8372-7e56b0126fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the basic query\n",
    "qry = session.query(LayerData.doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ae27095-ba44-4e1e-9f55-5fd7b831ccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x7f7c2e9ca150>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf55cfd7-5ca7-46ed-8962-0b1ce18c8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Filter for Grand Mesa, the specific date range, and density profiles\n",
    "qry = qry.filter(\n",
    "    LayerData.site_name == \"Grand Mesa\",\n",
    "    LayerData.date >= datetime(2019, 12, 1),\n",
    "    LayerData.date <= datetime(2020, 5, 31),\n",
    "    LayerData.type == 'lwc_vol'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc6c4756-528f-46d3-bcd1-3c39f1005e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique DOIs: ['lwc_vol']\n"
     ]
    }
   ],
   "source": [
    "# Get distinct DOIs only\n",
    "qry = qry.distinct()\n",
    "\n",
    "# Optional: Protect ourselves from excessive data with a limit\n",
    "qry = qry.limit(1000000000)\n",
    "\n",
    "# Execute the query and fetch all results\n",
    "result = qry.all()\n",
    "\n",
    "# Extract the DOIs from the results\n",
    "unique_dois = [r[0] for r in result]\n",
    "print('Unique DOIs:', unique_dois)\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86a9c306-e84c-49d1-998b-f933a9d55542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Types: ['sample_signal', 'force', 'density', 'grain_size', 'reflectance', 'permittivity', 'lwc_vol', 'manual_wetness', 'equivalent_diameter', 'specific_surface_area', 'grain_type', 'temperature', 'hand_hardness']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# This is what you will use for all of hackweek to access the db\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Query to get all unique types\n",
    "qry = session.query(LayerData.type).filter(\n",
    "    LayerData.site_name == \"Grand Mesa\",\n",
    "    LayerData.date >= datetime(2019, 12, 1),\n",
    "    LayerData.date <= datetime(2020, 5, 31)\n",
    ").distinct()\n",
    "\n",
    "available_types = qry.all()\n",
    "\n",
    "session.close()\n",
    "\n",
    "# Print available types\n",
    "print('Available Types:', [r[0] for r in available_types])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "630845ab-049d-470f-b049-a19725f28e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables: ['spatial_ref_sys', 'points', 'layers', 'sites', 'images']\n"
     ]
    }
   ],
   "source": [
    "# Reflect the tables in the database\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "# Create an inspector to view the schema\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get a list of all tables in the database\n",
    "tables = inspector.get_table_names()\n",
    "\n",
    "# Print the list of tables\n",
    "print(\"Available tables:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc632acc-4231-4303-bf4d-1f7b2c05b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doi.org/10.5067/DUD2VZEVBJ7S, https://doi.org/10.5067/KZ43HVLZV6G4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "# Form the SQL query to get distinct DOIs from the layers table\n",
    "qry = \"\"\"\n",
    "SELECT DISTINCT doi\n",
    "FROM layers\n",
    "WHERE site_name = 'Grand Mesa'\n",
    "AND date >= '2019-12-01'\n",
    "AND date <= '2020-05-31'\n",
    "AND type = 'density'\n",
    "\"\"\"\n",
    "\n",
    "# Establish a connection and execute the query\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(text(qry))\n",
    "\n",
    "    # Create a readable string to print the DOIs\n",
    "    # Access tuple values by index (0) since the results are tuples\n",
    "    out = ', '.join(row[0] for row in results)\n",
    "\n",
    "    # Print the distinct DOIs with a line return for readability\n",
    "    print(out + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21cf9e3-6257-483c-9a24-7e0ce2c28067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
